% ------------------------------------------------------------------------
% bjourdoc.tex for birkjour.cls*******************************************
% ------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{birkjour}
%
%
% THEOREM Environments (Examples)-----------------------------------------
%
 \newtheorem{thm}{Theorem}[section]
% \newtheorem{cor}[thm]{Corollary}
% \newtheorem{lem}[thm]{Lemma}
% \newtheorem{prop}[thm]{Proposition}
% \theoremstyle{definition}
 \newtheorem{defn}[thm]{Definition}
% \theoremstyle{remark}
% \newtheorem{rem}[thm]{Remark}
% \newtheorem*{ex}{Example}
 \numberwithin{equation}{section}

\usepackage[noadjust]{cite}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{tikz}
\begin{document}

%-------------------------------------------------------------------------
% editorial commands: to be inserted by the editorial office
%
%\firstpage{1} \volume{228} \Copyrightyear{2004} \DOI{003-0001}
%
%
%\seriesextra{Just an add-on}
%\seriesextraline{This is the Concrete Title of this Book\br H.E. R and S.T.C. W, Eds.}
%
% for journals:
%
%\firstpage{1}
%\issuenumber{1}
%\Volumeandyear{1 (2004)}
%\Copyrightyear{2004}
%\DOI{003-xxxx-y}
%\Signet
%\commby{inhouse}
%\submitted{March 14, 2003}
%\received{March 16, 2000}
%\revised{June 1, 2000}
%\accepted{July 22, 2000}
%
%
%
%---------------------------------------------------------------------------
%Insert here the title, affiliations and abstract:
%


\title[Solve 2D Poisson Equation on 3D meshes]
 {Solve 2D Poisson Equation on 3D meshes}

%----------Author 1
\author[Mauricio Cele Lopez Belon]{Mauricio Cele Lopez Belon}
\address{Madrid, Spain}
\email{mclopez@outlook.com}

%----------classification, keywords, date
\subjclass{Parallel algorithms 68W10; Clifford algebras, spinors 15A66}

\keywords{Geometric Algebra, Quaternion Estimation, Mesh Deformation}

\date{October 21, 2024}
%----------additions
%\dedicatory{To my wife}
%%% ----------------------------------------------------------------------

\begin{abstract}

Solve 2D Poisson's equation with Dirichlet boundary conditions on a 3D mesh using Finite Element Method (FEM).

\end{abstract}

%%% ----------------------------------------------------------------------
\maketitle
%%% ----------------------------------------------------------------------
%\tableofcontents
\section{Introduction}


This follows the method described in \cite{Sayas2015} and \cite{Langtangen2014}.

We aim to solve Poisson's equation 
\begin{eqnarray}
	- \bigtriangleup U(x, y) = F(x, y)
\end{eqnarray}
where 
\begin{eqnarray}
	\bigtriangleup U(x,y) = \nabla \cdot \nabla \ U(x,y)
\end{eqnarray}
with Dirichlet boundary conditions using Finite Element Method (FEM).

In 2D it can be written as:
\begin{eqnarray}
 - U(x, y)_{xx} - U(x, y)_{yy} = F(x,y)  \ \ \   in \ \Omega \nonumber\\
U(x,y) = G(x,y)   \ \ \   in \ \partial \Omega \nonumber
\end{eqnarray}

The integral form (notice $\int_{\Omega}$ is a double integral):
\begin{eqnarray}
 - \int_{\Omega} { \bigtriangleup U(x,y) \ dA } = \int_{\Omega} { F(x,y) \ dA }
\end{eqnarray}

\section{Weak Form}

The weak form comes from the ``variational method''. Here one tries to get a solution to the 
PDE by translating it into a minimization problem. That's done by definig an energy function that is a 
linear functional on a function space $\Omega$. The linear functional is artificial i.e., pure 
mathematical device to enable optimization. In consequence, solving the variational problem may 
require less continuity than that of the actual solution (hence the name WEAK form).
 
Consider the weight function $\vartheta (x,y)$ (a.k.a. test function) with compact support defined on $\Omega$.
The ``Galerkin'' variational method states that the inner product of $\vartheta(x,y)$ with a residual function $R(x,y)$ should be zero.

\begin{eqnarray}
	\int_{\Omega} { \vartheta(x, y) R(x,y) \ dA } = 0 \nonumber
\end{eqnarray}
 where $R(x,y)$ is the residual or error of the function i.e., 
\begin{eqnarray}
	R(x,y) = - \bigtriangleup U(x,y) - F(x,y) \nonumber
\end{eqnarray}
The weak form of the PDE is:
\begin{eqnarray}
	\vartheta(x, y) R(x,y) = 0 \nonumber\\
	\vartheta(x, y) (- \bigtriangleup U(x,y) - F(x,y)) = 0 \nonumber\\
	- \vartheta(x,y) \bigtriangleup U(x,y) = F(x,y) \vartheta(x,y) \nonumber
\end{eqnarray}
 and the integral (variational) form of the PDE is
\begin{eqnarray}
	\label{eqn:original_weak_form}
	- \int_{\Omega}{ \vartheta(x,y) \bigtriangleup U(x,y) \ dA } = \int_{\Omega} { F(x,y) \vartheta(x,y) \ dA }
\end{eqnarray}
NOTE on inner products: The integral form is more important since integral of the product 
of two functions $f(x,y)$ and $g(x,y)$ is the ``inner product'' $\int_{\Omega}{ f(x,y) g(x,y) \ dA }$.
If function $g(x,y)$ is a ``test function" then the inner product is way to ``measure'' the 
function $f(x,y)$ on location where $g(x,y)$ is defined. Since $g(x,y)$ is not the Dirac Delta 
function then the measure is an averaged one.
 
Consider the vector field
\begin{eqnarray}
	E(\vec X) = \vartheta(\vec X) \nabla U(\vec X)
\end{eqnarray}
 
Taking $\nabla \cdot E(\vec X)$ by Green's first identity we get:
\begin{eqnarray}
	\label{eqn:green_first_identity}
	\nabla \cdot E = \nabla \cdot (\vartheta \ \nabla U) \nonumber\\
	\nabla \cdot E = \nabla \vartheta \cdot \nabla U + \vartheta \bigtriangleup U
\end{eqnarray} 

By applying the Divergence theorem:
\begin{eqnarray}
	\label{eqn:divergence_theorem}
	\int_{\Omega} {\nabla \cdot E \ dA} = \int_{\partial \Omega} { E \cdot n  \ dS }
\end{eqnarray}
where $n(\vec X)$ is the normal to the boundary $\partial \Omega$

Replacing (\ref{eqn:green_first_identity}) on (\ref{eqn:divergence_theorem}) we get:
\begin{eqnarray}
	\int_{\Omega}{ \nabla \vartheta \cdot \nabla U + \vartheta \bigtriangleup U  \ dA} = \int_{\partial \Omega} {  E \cdot n  \ dS } \nonumber
\end{eqnarray}

By definition of $E(\vec X) = \vartheta(\vec X) \nabla U(\vec X)$ the RHS becomes:
\begin{eqnarray}
	\int_{\Omega}{ \nabla \vartheta \cdot \nabla U + \vartheta \bigtriangleup U  \ dA} = \int_{\partial \Omega} { \vartheta \nabla U \cdot n  \ dS } \nonumber \\
	= \int_{\partial \Omega} { \vartheta \left( \nabla U \cdot n\right) dS }
\end{eqnarray}
since test function $\vartheta(\vec X)$ can be considered ``constant'' at the boundary.

So we can re-arrange the left-hand-side to get:
\begin{eqnarray}
	\int_{\Omega}{\vartheta \bigtriangleup U  \ dA} = \int_{\partial \Omega} { \vartheta \left( \nabla U \cdot n\right)  \ dS } - \int_{\Omega}{ \nabla \vartheta \cdot \nabla U  \ dA}
\end{eqnarray}

Replacing the left-hand-side of our variational form of PDE (\ref{eqn:original_weak_form}) with the above we get:
 \begin{eqnarray}
	-\int_{\partial \Omega} { \vartheta \left( \nabla U \cdot n \right)  \ dS } + \int_{\Omega}{ \nabla \vartheta \cdot \nabla U  \ dA} = \int_{\Omega} { F \ \vartheta  \ dA }
\end{eqnarray}
giving the standard weak form:
\begin{eqnarray}
	\label{eqn:standard_weak_form}
	\int_{\Omega}{ \nabla \vartheta \cdot \nabla U  \ dA} = \int_{\Omega} { F \cdot \vartheta  \ dA } + \int_{\partial \Omega} { \vartheta \left( \nabla U \cdot n\right)  \ dS }
\end{eqnarray}

We now define that all $\vartheta(\vec X)$ at the boundary $\partial \Omega$ has zero value, 
which is a necessary condition for the variational problem to converge e.g., test function must have compact support.
\begin{eqnarray}
	\vartheta(\vec X) = 0  \ \ \  \forall \vec X \in \ \partial \Omega
\end{eqnarray}
 
So the weak form is now:
\begin{eqnarray}
	\label{eqn:weak_form}
	\int_{\Omega}{ \nabla \vartheta \cdot \nabla U  \ dA} = \int_{\Omega} { F \ \vartheta  \ dA }
\end{eqnarray}


\section{Discretization}
\label{sec:discretization} 

The domain $\Omega$ has to be meshed in $N$ nodes and $T$ triangles. For linear elements the nodes coincides with 
mesh vertices (but for quadratic elements there will be nodes defined on the triangle's edge mid-points, 
so there can be more nodes than vertices).

The first discretisation is easy. We discretize the test functions 
\begin{eqnarray}
	\label{eqn:test_function}
	\vartheta(\vec X) = \sum_i { \varphi_i(\vec X) }
\end{eqnarray} 
as a linear combination of $\varphi_i(\vec X)$ over the entire domain $\Omega$. $\varphi_i(\vec X)$ is a function with compact support 
defined at every node of $\Omega$ to be equal to $1$ at center node $\vec N_i$, equal to $0$ at 
sorrounding nodes $N_j$ and linear everywhere else inside triangles in triangle-set $\Omega_i$ a.k.a., a tent function:
\begin{eqnarray}
	\varphi_j(\vec N_j) = 1 \ \ \  \forall j = i \nonumber\\
	\varphi_j(\vec N_j) = 0 \ \ \  \forall j \neq i \nonumber\\
	\varphi_j(\vec X) = linear \ in \ \Omega_i \nonumber
\end{eqnarray}
when restricted to individual triangle, test functions defined at nodes are also known as barycentric coordinates of triangles.

Plugging (\ref{eqn:test_function}) into (\ref{eqn:weak_form}) we get a system of integral equations, 
one equation per triangle-set $\Omega_i$ corresponding to the compact
support of test function $\varphi_i(\vec X)$:
\begin{eqnarray}
	\int_{\Omega}{ \nabla \sum_i { \varphi_i } \cdot \nabla U\ dA} = \int_{\Omega} { F \sum_i {\varphi_i} \ dA } \nonumber\\
	\int_{\Omega}{\sum_i { \nabla \varphi_i \cdot \nabla U} \ dA} = \int_{\Omega} { \sum_i {F \ \varphi_i} \ dA } \nonumber\\
	\sum_i { \int_{\Omega}{ \nabla \varphi_i \cdot \nabla U \ dA}} = \sum_i { \int_{\Omega} { F \ \varphi_i} \ dA } \nonumber	
\end{eqnarray}
where the integrals are now much smaller i.e., per triangle-set $\Omega_i$ around nodes $\vec N_i$ or tent function $\varphi_i(\vec X)$

The second discretization is of solution $U(\vec X)$. We define the global solution $U(\vec X)$ to be a finite sum:
\begin{eqnarray}
	\label{eqn:solution_u}
	U(\vec X) = \sum_j^N{ U_j \psi_j(\vec X) }
\end{eqnarray}
where $U_j$ are coefficients to be determined at each node on entire domain $\Omega$ and $\psi_j(\vec X)$ are the 
so-called ``shape functions'' (i.e., interpolation functions) also defined with compact support of triangle-sets $\Omega_i$.

Functions defined on triangle-set $\Omega_i$ around node $\vec N_i$ to be equal to $1$ at center node $\vec N_i$, equal to $0$ at 
sorrounding nodes $N_j$ and linear everywhere else at triangles in $\Omega_i$ a.k.a., a tent function also known as P1 linear functions.
\begin{eqnarray}
	\psi_j(\vec N_j) = 1 \ \ \  \forall j = i  \nonumber\\
	\psi_j(\vec N_j) = 0 \ \ \  \forall i \neq j \nonumber\\
	\psi_j(\vec X) = linear \ in \ \Omega_i \nonumber
\end{eqnarray}
when restricted to individual triangles, shape functions are also known as barycentric coordinates of triangles.

At this point we can see $\varphi_i(\vec X)$ and $\psi_i(\vec X)$ are the same, but they don't have to be the same. 
When those that the same the FEM is so-called ``Galerkin FEM''. 

The third discretization is of the gradients $\nabla U(\vec X)$ and $\nabla \vartheta(\vec X)$ 
using (\ref{eqn:solution_u}) and (\ref{eqn:test_function}). The grandient of $U(\vec X)$ 
is just the linear combination of gradients at the triangle nodes:
\begin{eqnarray}
	\label{eqn:gradient_u}
	\nabla U(\vec X) = \nabla \left(\sum_i {U_i \psi_i(\vec X)} \right) \nonumber\\
	\nabla U(\vec X) = \sum_i { U_i \nabla \psi_i(\vec X) }
\end{eqnarray}
where the las equality holds by product rule. The gradient is defined in terms of $\nabla \psi_i(\vec X)$ and 
$U_i$ can be treated as a ``constant'' coefficient 
that need to be determined at every node. Note that triangles sharing vertices also shares the same $U_i$ coefficient. 
$\nabla U(\vec X)$ is a smooth function inside triangles so it gives us a ``continuous'' gradient at the whole $\Omega$.

The gradient of test functions, is defined in the same manner:
\begin{eqnarray}
	\label{eqn:gradient_v}
	\nabla \vartheta(\vec X) = \sum_i { \nabla \varphi_i(\vec X) }
\end{eqnarray}

Now we can discretize the inner product $\langle \nabla \vartheta(\vec X), \nabla U(\vec X)\rangle$ which is characteristic of the Laplacian:
\begin{eqnarray}
	\label{gradient_inner_product}
	\nabla \vartheta \cdot \nabla U = \sum_i { \nabla \varphi_i } \cdot \sum_j { U_j \nabla \psi_j } \nonumber\\
	= \sum_{i,j} { \nabla \varphi_i \cdot U_j \nabla \psi_j } \nonumber\\
	= \sum_{ij} {U_j \left( \nabla \varphi_i \cdot \nabla \psi_j \right)}
\end{eqnarray}
summation inidices run for all connected nodes $i$ and $j$.

Plugging (\ref{gradient_inner_product}) into (\ref{eqn:weak_form}) we get a system of linear equations
\begin{eqnarray}
	\int_{\Omega}{  \nabla \vartheta \cdot \nabla U \ dA}  = \int_{\Omega}{ \sum_{ij} {U_j \left( \nabla \varphi_i \cdot \nabla \psi_j \right) } \ dA}  \nonumber\\
	= \sum_{ij} {U_j \int_{\Omega}{ \nabla \varphi_i \cdot \nabla \psi_j \ dA }}  \nonumber
\end{eqnarray}

So we get the following system of linear equations:
\begin{eqnarray} 
	\sum_{ij} {U_j \int_{\Omega}{ \nabla \varphi_i \cdot \nabla \psi_j \ dA}} = \sum_i { \int_{\Omega}{ F \ \varphi_i \ dA }}
\end{eqnarray}

Which can be written in matrix form as follows. First define a set of ``stiffness'' matrices $M_T^i$ per triangle 
of size $N \times N$ defined as:
\begin{eqnarray} 
	M_T^k(i,j) = \int_{T}{ \nabla \varphi_i \cdot \nabla \psi_j \ dA} \nonumber
\end{eqnarray}
inidices $(i,j)$ run for all nodes of triangle $T$.

Then the $N \times 1$ boundary conditions vector $F_i$:
\begin{eqnarray} 
	F_i  = \int_{\Omega}{ F \ \varphi_i \ dA } \nonumber
\end{eqnarray}

The $N \times N$ stiffness matrix $M$ can be assembled as $M = \sum_k M_T^k$ and boundary conditions can be assembled as $F = \sum_i F_i$ to 
form a global $N \times N$ matrix system (we choose to have shape functions $\psi_i$ equal to test functions $\varphi_i$ so 
we have same number of equations than unknowns)

\begin{eqnarray} 
	M U = F
\end{eqnarray}

\section{Assembly}


The process of creating the stiffness matrix $M$ is called assembly. It consist of creating the matrix $M_k$ for each 
triangle $T_k$ and then add it to the global $M$ matrix. 
 
The global matrix $M$ is $N \times N$  where $N$ is number of mesh nodes. In previous section~\ref{sec:discretization}
the matrix $M_k$ is a $N \times N$ super-sparse matrix just with a few non-zero entries which corresponds to a single 
triangle contribution.
 \begin{eqnarray} 
	M = \sum_k M_k
\end{eqnarray}
 
In practice the $M_k$ matrix is not $N \times N$ super-sparse, but a $3 \times 3$ matrix (in case of linear triangle elements).
There is a map from indices of the $3 \times 3$ matrix to the $N \times N$ matrix as follows.
 
Each triangle's nodes has a global index assigned in the mesh, we also establish a local indexing of triangle
like $1$, $2$ and $3$. We define a trivial bijective map between global and local indices.

\section{Reference Elements}

One of the novelties of FEM is to be able to compute the integrals per individual elements on an easy and generic 
way by using so called Reference Elements.
 
For triangle elements we just need a single reference triangle
 
\begin{center}
	\begin{tikzpicture}
		\draw (0,0) node[anchor=south]{$P_3$}
		-- (0,-3) node[anchor=north]{$P_1$}
		-- (3,-3) node[anchor=north]{$P_2$}
		-- cycle;
	\end{tikzpicture}		
\end{center}
\begin{eqnarray} 
	P_1 = (0,0) \nonumber\\
	P_2 = (1,0) \nonumber\\
	P_3 = (0,1) \nonumber
\end{eqnarray}

The P1 (linear) 2D Lagrange shape functions $\psi(u,v)$ has the form 
\begin{eqnarray} 
	\psi(u,v) = A u + B u + C \nonumber
\end{eqnarray}

For the reference trignale defined above the $\psi(u,v)$ takes the simple form:
\begin{eqnarray} 
	\psi_1(u,v) = 1 - u - v \nonumber\\
	\psi_2(u,v) = u \nonumber\\
	\psi_3(u,v) = v \nonumber
\end{eqnarray}

We can check that $\psi_i \cdot \psi_j = \delta_{ij}$
\begin{eqnarray} 
\psi_1(P_1) = 1 \ \  \psi_1(P_2) = 0  \ \  \psi_1(P_3) = 0 \nonumber\\
\psi_2(P_1) = 0 \ \  \psi_2(P_2) = 1  \ \  \psi_2(P_3) = 0 \nonumber\\
\psi_3(P_1) = 0 \ \  \psi_3(P_2) = 0  \ \  \psi_3(P_3) = 1 \nonumber
\end{eqnarray}

We define a function $F(\vec U)$, a.k.a., \emph{pushforward}, that maps reference 2D triangle to "physical" 2D triangle on the mesh
(the inverse $F^{-1}(\vec X)$ , a.k.a., \emph{pullback}, maps triangle from physical to reference frame).
\begin{eqnarray}
	\left[\begin{array}{c}
		x \\
		y
	\end{array}\right] = 
	\left[\begin{array}{cc}
		x_2 - x_1 &  x_3 - x_1 \\
		y_2 - y_1 &  y_3 - y_1
	\end{array}\right] 
	\left[\begin{array}{c}
		u \\
		v
	\end{array}\right] +
	\left[\begin{array}{c}
		x_1 \\
		y_1
	\end{array}\right] \nonumber
\end{eqnarray}

Which cab be expressed in vector form
\begin{eqnarray} 
	F(\vec U) =  B \vec U + \vec X_1 \nonumber\\
	F^{-1}(\vec X)  = B^{-1} (\vec X - \vec X_1) \nonumber
\end{eqnarray}


We denote $\psi^k_i$ the function $\psi_i$ defined on physical triangle $K$.

\begin{eqnarray} 
	\psi^k_i(\vec X) = \psi_i \circ  F^{-1}(\vec X) \nonumber\\
	\psi^k_i(\vec X) = \psi_i( F^{-1}(\vec X) ) \nonumber
\end{eqnarray}

The gradient of $\psi^k_i(\vec X)$ in physical triangle is:

\begin{eqnarray} 
	\nabla_{\vec X} \psi^k_i(\vec X) = \nabla_{\vec X} \psi_i( F^{-1}(\vec X) ) \nonumber\\
    = \nabla_{\vec U} \psi_i( \vec U ) \cdot \nabla_{\vec X} F^{-1}(\vec X) \nonumber\\
    = B^{-T} \nabla_{\vec U} \psi_i( \vec U) \nonumber
\end{eqnarray}
where we used $\vec U = F^{-1}(\vec X)$ and $\nabla_{\vec X} F^{-1}(\vec X) = B^{-T}$.

The gradient of $\psi_i(\vec U)$ in reference triangle is:

\begin{eqnarray} 
	\nabla \psi_1 = (-1, -1) \nonumber\\
	\nabla \psi_2 = (1, 0) \nonumber\\
	\nabla \psi_3 = (0, 1) \nonumber
\end{eqnarray}

So the gradient of $\psi^k_i(\vec X)$ in physical triangle is ``constant'':
 
\begin{eqnarray} 
	\nabla \psi^k_1 = B^{-T} (-1, -1) \nonumber\\
	\nabla \psi^k_2 = B^{-T} (1, 0) \nonumber\\
	\nabla \psi^k_3 = B^{-T} (0, 1) \nonumber
\end{eqnarray}

\subsection{For 3D Triangles}

For 3D triangles the map function $F$ changes as follows:
\begin{eqnarray}
	\left[\begin{array}{c}
		x \\
		y \\
		z
	\end{array}\right] = 
	\left[\begin{array}{cc}
		x_2 - x_1 &  x_3 - x_1 \\
		y_2 - y_1 &  y_3 - y_1 \\
		z_2 - z_1 &  z_3 - z_1
	\end{array}\right] 
	\left[\begin{array}{c}
		u \\
		v
	\end{array}\right] +
	\left[\begin{array}{c}
		x_1 \\
		y_1 \\
		z_1
	\end{array}\right] \nonumber
\end{eqnarray}

In matrix algebra it can be expressed as:

\begin{eqnarray}
	F(\vec U) = B \vec U + \vec X_1 \nonumber\\
	F^{-1}(\vec X) = (B^T B)^{-1} B^T (\vec X - \vec X_1)  \nonumber
\end{eqnarray}
or
\begin{eqnarray}
	F^{-1}(\vec X) = B^{-*} (\vec X - \vec X_1) \nonumber
\end{eqnarray}
where $B^{-*} = (B^T B)^{-1} B^T$ is the Moore-Penrose pseudo-inverse of $B$.

The same analysis as before holds so:

\begin{eqnarray} 
	\nabla \psi^k_1 = B^{-*T} (-1, -1) \nonumber\\
	\nabla \psi^k_2 = B^{-*T} (1, 0) \nonumber\\
	\nabla \psi^k_3 = B^{-*T} (0, 1) \nonumber
\end{eqnarray}
 
\section{Numerical Quadrature}

The entries of the matrix $M_T^k$ are the following double integrals:

\begin{eqnarray} 
	M_T^k(i,j) = \int_{T^k}{ \nabla \psi^k_i(\vec X) \cdot \nabla \psi^k_j(\vec X) \ dA} \nonumber
\end{eqnarray}
inidices $(i,j)$ run for all nodes of triangle $T$.
 
Let define the inner product of basis functions as  

\begin{eqnarray} 
	I^k_{ij}(\vec X) = \nabla \psi^k_i(\vec X) \cdot \nabla \psi^k_j(\vec X) \nonumber
\end{eqnarray}

The 3-point Gauss quadrature rule for the linear triangle is:
\begin{eqnarray} 
	M_T^k(i,j) = \frac{area(T^k)}{3} ( I^k_{ij}(P_1) +  I^k_{ij}(P_2) +  I^k_{ij}(P_3))
\end{eqnarray}
evaluated at the vertices of the triangle $P_1$, $P_2$ and $P_3$. Which is an exact quadrature formula 
for linear function on a triangle. However since $\nabla \psi^k_i(\vec X)$ does not depends on $\vec X$ the quadrature 
expression reduces to:
\begin{eqnarray} 
	M_T^k(i,j) = area(T^k) \nabla \psi^k_i(\vec X) \cdot \nabla \psi^k_j(\vec X) \nonumber
\end{eqnarray}


\iffalse
* 
* APPRENDIX - USINF DIFFERENTIAL FORMS
* 
* d = exterior derivative
* * = Hodge dual
* f(x,y) = scalar valued function (scalar field) : 0-form
* g(x,y) = vector valued function (vector-field): 1-form
* df(x,y) = gradient vector field : 1-form
* *d* g(x,y) = divergence of g(x,y): 0-form
* 
* *df(x,y): dual of the 1-form in R^2: 1-form (in dual space)
* d*df(x,y): curl of the 1-form in the cotangent space: 2-form
* *d*df(x,y): divergence of gradient: 0-form
* 
* U(x,y) = twice differentiable scalar valued function (scalar field) : 0-form
* 
* Laplace-Beltrami operator: d∗d + dd∗
* 
* Laplacian-Beltrami equation: d*d U(x,y) = *f(x, y)                Since dd* U(X) = 0 
* 
* In this equation d*d U(x,y) and *f(x, y) are 2-forms (pseudo-scalar fields)
* 
* R(X) = d*d U(X) - *f(X)
* 
* minimize Integral V(X) R(X)
* 
* Integral V(X) R(X) = 0    (Optimality condition for the variational form)
* 
* Integral V(X) d*d U(X) = Integral V(X) *f(X)
* 
* Recall product rule: d ( V(X) dU(X) ) = dV(X)^dU(X) + V(X) ddU(X)
* 
* Consider the vector field E(X) = V(X) *dU(X)
* 
* Taking d E(X) we get:
* 
* d E(X) = d (V(X) *dU(X))
*        = dV(X)^(*dU(X)) + V(X) d*dU(X)    (by product rule)
* 
* Since wedge product of a k-form with a (N-k)-form is same as inner product: V(X)^*U(X) = <V(X), U(X)>
* 
* d E(X)  = <dV(X), dU(X)> + V(X) d*d U(X)
* 
* By applying the Stokes theorem to Integral_D d E(X):
* 
* Integral_D( d E(X) dA ) = Integral_#D ( E(X) dS )                      By Stokes theorem
*                         = Integral_#D V(X)^*dU(X) dS
*                         = Integral_#D V(X) <dU(X), dS>
* 
* We get
* 
* Integral_D( <dV, dU> + V  d*dU dA) = Integral_#D V(X) <dU(X), dS>
* 
* So we can re-arrange as:
* 
* Integral_D V  d*dU dA = Integral_#D V(X) <dU(X), dS> - Integral_D < dV, dU> dA
* We have performed essentially Integration By Parts. Replacing into the left-hand-side 
* of the variational form we get:
* 
* Integral_#D V(X) <dU(X), dS> - Integral_D < dV, dU> dA = Integral V(X) *f(X)
* 
* Since V(X) = 0 on the boundary of the domain #D then we get:
* 
* - Integral_D < dV, dU> dA = Integral V(X) *f(X)
\fi

\section{Implementation}

Implementation can be found in \cite{Basic2DFEM}

\section{Appendix - Differential Forms}

\newcommand{\hodge}{{\star}}

\begin{tabular}{l l}
	$d$ & exterior derivative\\
	$\hodge$ & Hodge dual\\
	$f(x,y)$ & scalar valued function (scalar-field) : 0-form\\
	$g(x,y)$ & vector valued function (vector-field): 1-form\\
	$df(x,y)$ & gradient vector field : 1-form\\
	$\hodge d \hodge g(x,y)$ & divergence  of  g(x,y): 0-form\\
	$\hodge df(x,y)$ & dual  of  the  1-form  in  $R^2$:  1-form (in dual space)\\
	$d \hodge df(x,y)$ & curl of the 1-form in the cotangent space: 2-form\\
	$\hodge d \hodge df(x,y)$ & divergence of gradient: 0-form\\
	$U(x,y)$ & twice differentiable scalar-valued function\\ & (scalar field) : 0-form\\
	$d \hodge d + d d \hodge$ & Laplace-Beltrami operator\\
	$d \hodge d U(x,y) = \hodge f(x, y)$ & Laplacian-Beltrami equation, since $dd\hodge U(X) = 0$ \\
\end{tabular}

Laplacian-Beltrami equation:
\begin{eqnarray} 
	d \hodge d U(x,y) = \hodge f(x, y) \nonumber
\end{eqnarray} 
the $d \hodge d U(x,y)$ and $\hodge f(x, y)$ are 2-forms (pseudo-scalar fields). The residual $R(X)$ is
\begin{eqnarray} 
	R(X) = d \hodge d U(X) - \hodge f(X) \nonumber
\end{eqnarray} 
So we want to minimize $\int V(X) R(X)$ using Galerkin method we get the optimality condition for the variational form:
\begin{eqnarray} 
\int V(X) R(X) = 0 \nonumber\\
\int V(X) \ d \hodge d U(X) = \int V(X) \ \hodge f(X) \nonumber
\end{eqnarray} 

Recall product rule:
\begin{eqnarray} 
	d \left( V(X) d U(X) \right) = d V(X) \wedge d U(X) + V(X) \ d d U(X) \nonumber
\end{eqnarray} 
	
Consider the vector field $E(X) = V(X) \hodge d U(X)$ where $V(X)$ and $ \hodge d U(X)$ are 0-forms. Taking $d E(X)$ we get:
\begin{eqnarray} 
	d E(X) = d \left( V(X) \ \hodge dU(X) \right) \nonumber\\
	d E(X) = d V(X) \wedge \hodge d U(X) + V(X) \ d \hodge d U(X) \nonumber
\end{eqnarray} 

Since wedge product of a k-form with a (N-k)-form is same as inner product:
\begin{eqnarray} 
	V(X) \wedge \hodge U(X) = V(X) \cdot U(X) \nonumber\\
	V(X) \wedge \hodge U(X) = V(X) U(X) \nonumber
\end{eqnarray}
The last equality holds when $V(X)$ and $U(X)$ are 0-forms. Then we can re-write $d E(X)$ as:
\begin{eqnarray} 
	d E(X)  = dV(X) \cdot dU(X) + V(X) \ d \hodge d \ U(X) \nonumber
\end{eqnarray} 

By applying the Stokes theorem to $\int_{\Omega} d E(X)$:
\begin{eqnarray} 
\int_{\Omega}{ d E(X) \ dA } = \int_{\partial \Omega} { E(X) \ dS }   \nonumber\\
\int_{\Omega}{ d E(X) \ dA } = \int_{\partial \Omega} { V(X) \wedge *dU(X) \ dS } \nonumber\\
\int_{\Omega}{ d E(X) \ dA } = \int_{\partial \Omega} { V(X) dU(X) \cdot dS } \nonumber
\end{eqnarray} 
the last equality holds since $V(X) \cdot dU(X) = V(X) dU(X)$ since $V(X)$ is 0-form and $dU(X)$ is a 1-form. Also
since $dS$ is a 1-form the product of $dU(X) dS$ is actually $dU(X) \cdot dS$.

Replacing left hand side:
\begin{eqnarray} 
	\int_{\Omega}{dV(X) \cdot dU(X) + V(X) \ d \hodge d \ U(X) \ dA} = \int_{\partial \Omega} { V(X) dU(X) \cdot dS }
\end{eqnarray}

So we can re-arrange as:
\begin{eqnarray} 
\int_{\Omega} {V(X) \ d \hodge d \ U(X) \ dA} = \int_{\partial \Omega} {V(X) dU(X) \cdot dS} - \int_{\Omega} {dV(X) \cdot dU(X) \ dA}
\end{eqnarray}

We have performed essentially Integration By Parts. Replacing into the left-hand-side 
of the variational form we get:
\begin{eqnarray} 
\int_{\Omega} { V(X) \ d \hodge d U(X) \ dA } = \int_{\Omega} { V(X) \hodge f(X) \ dA } \nonumber\\
\int_{\partial \Omega} { V(X) dU(X) \cdot dS } - \int_{\Omega} {dV(X) \cdot dU(X) \ dA} = \int_{\Omega} { V(X) \hodge f(X) \ dA } \nonumber
\end{eqnarray}
 
Since $V(X) = 0$ on the boundary of the domain $\partial \Omega$ then we get:

\begin{eqnarray} 
	- \int_{\Omega} { dV(X) \cdot dU(X) \ dA } = \int_{\Omega} { V(X) \hodge f(X) \ dA } \nonumber
\end{eqnarray}


\bibliographystyle{abbrv}
\bibliography{fembasic2d}

% ------------------------------------------------------------------------
\end{document}
% ------------------------------------------------------------------------
